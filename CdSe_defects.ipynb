{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe1a73df",
   "metadata": {},
   "source": [
    "#Defects Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b19c970e-68e7-4c09-a90b-a2c5516b035c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import h5py\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torchsummary import summary\n",
    "import torchvision.models\n",
    "from tqdm import tqdm\n",
    "from skimage.measure import label as separate_labels\n",
    "fp_data = \"CdSe\\Dataset\\CdSe_defect_dataset.h5\"\n",
    "fp_metadata =\"CdSe\\Metadata\\CdSe_metadata.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5026b634-188a-4044-a82d-be74f6eada4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_multi_labels(orig_mask, df, idx):\n",
    "    N_particles = df.iloc[idx][\"N_particles\"]\n",
    "    multi_mask = separate_labels(orig_mask)\n",
    "\n",
    "    if np.max(multi_mask) != N_particles:\n",
    "        print(\"Image %i does not have enough particles\" % i)\n",
    "        return False, []\n",
    "    else:\n",
    "        return True, [multi_mask == i+1 for i in range(N_particles)]\n",
    "\n",
    "def print_positions(df, idx):\n",
    "\n",
    "    N_particles = df.iloc[idx][\"N_particles\"]\n",
    "\n",
    "    for i in range(N_particles):\n",
    "        print(df.iloc[idx][\"particle_%02i\" % i][\"position\"])\n",
    "\n",
    "def get_positions(df, idx):\n",
    "\n",
    "    N_particles = df.iloc[idx][\"N_particles\"]\n",
    "\n",
    "    return [df.iloc[idx][\"particle_%02i\" % i][\"position\"] for i in range(N_particles)]\n",
    "\n",
    "def get_centroid(particle_label, cal_px_size, xx, yy):\n",
    "    \"\"\"Takes in a particle label, pixel size, and premade meshgrid to calculate centroid of a region.\"\"\"\n",
    "\n",
    "    centroid_x = np.sum(xx*particle_label)/np.sum(particle_label)\n",
    "    centroid_y = np.sum(yy*particle_label)/np.sum(particle_label)\n",
    "\n",
    "    return [centroid_x*cal_px_size, centroid_y*cal_px_size]\n",
    "\n",
    "def get_centroids(multi_labels, cal_px_size, xx, yy):\n",
    "    \"\"\"Wrapper function to get all the centroids from a set of labels\"\"\"\n",
    "    return np.array([get_centroid(multi_labels[i], cal_px_size, xx, yy) for i in range(len(multi_labels))])\n",
    "\n",
    "def pair_labels_to_particles(centroids, pos):\n",
    "    \"\"\"Pairs segmentation labels to particle indices, per image.\n",
    "\n",
    "    Centroids are the centroids of the individual particle segmentation masks, scaled to atomic coordinates.\n",
    "    Pos are the centers of the particles in x and y in atomic coordinates.\n",
    "    \n",
    "    Returns a list of length N_particles with tuples (i,j), matching the i-th particle to the j-th segmentation mask.\n",
    "    \"\"\"\n",
    "\n",
    "    # shift centroid array and position array to have common origin\n",
    "    centroids = centroids - np.min(centroids, axis=0)\n",
    "    pos = pos - np.min(pos, axis=0)\n",
    "\n",
    "    # pair particle to mask by taking index of closest mask centroid\n",
    "    pairs =[]\n",
    "    for i, p in enumerate(pos):\n",
    "        dists = np.linalg.norm(centroids-p, axis=1)\n",
    "        pairs.append((i, np.argmin(dists)))\n",
    "    return pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "508cf256-f38c-4194-9919-2e7cb7c3e42b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "cannot instantiate 'PosixPath' on your system",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_75884\\548148516.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m# reduce metadata data frame to just the columns we need\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mmetadata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_pickle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[0mmetadata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"N_particles\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"particle_00\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"particle_01\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"particle_02\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"particle_03\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"particle_04\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\maste\\anaconda3\\envs\\pyT\\lib\\site-packages\\pandas\\io\\pickle.py\u001b[0m in \u001b[0;36mread_pickle\u001b[1;34m(filepath_or_buffer, compression, storage_options)\u001b[0m\n\u001b[0;32m    215\u001b[0m                     \u001b[1;31m# RawIOBase, BufferedIOBase, TextIOBase, TextIOWrapper, mmap]\";\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    216\u001b[0m                     \u001b[1;31m# expected \"IO[bytes]\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 217\u001b[1;33m                     \u001b[1;32mreturn\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandles\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[arg-type]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    218\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mexcs_to_catch\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m                 \u001b[1;31m# e.g.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\maste\\anaconda3\\envs\\pyT\\lib\\pathlib.py\u001b[0m in \u001b[0;36m__new__\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1028\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_flavour\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_supported\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1029\u001b[0m             raise NotImplementedError(\"cannot instantiate %r on your system\"\n\u001b[1;32m-> 1030\u001b[1;33m                                       % (cls.__name__,))\n\u001b[0m\u001b[0;32m   1031\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_init\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1032\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotImplementedError\u001b[0m: cannot instantiate 'PosixPath' on your system"
     ]
    }
   ],
   "source": [
    "# Load data and metadata\n",
    "cdse_data = h5py.File(fp_data,\"r\")\n",
    "\n",
    "X_all = np.array(cdse_data[\"data\"])\n",
    "Y_all = np.array(cdse_data[\"masks\"])\n",
    "\n",
    "cdse_data.close()\n",
    "\n",
    "# reduce metadata data frame to just the columns we need\n",
    "metadata = pd.read_pickle(fp_metadata)\n",
    "metadata = metadata[[\"N_particles\", \"particle_00\", \"particle_01\", \"particle_02\", \"particle_03\", \"particle_04\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cabd5da-8ec0-4608-8fc7-fbad57aa9564",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_particles_total = metadata[\"N_particles\"].sum()\n",
    "\n",
    "# initialize data for particle-mask pairing\n",
    "px_size = 0.2 # angstroms\n",
    "yy, xx = np.meshgrid(np.arange(512),np.arange(512))\n",
    "\n",
    "# preallocate new arrays\n",
    "X_new = np.zeros(shape=(N_particles_total,512,512), dtype='float32')\n",
    "mask_new = np.zeros(shape=(N_particles_total, 512, 512), dtype='float32')\n",
    "Y_new = np.zeros(shape=(N_particles_total,2), dtype='float32')\n",
    "\n",
    "# for each image\n",
    "count = 0 # running index\n",
    "for i in tqdm(range(X_all.shape[0])):\n",
    "    # get the multilabels\n",
    "    success, multi_labels = make_multi_labels(Y_all[i], metadata, i)\n",
    "\n",
    "    if not success:\n",
    "        continue\n",
    "\n",
    "    # pair labels to positions\n",
    "    pos = np.array(get_positions(metadata, i))\n",
    "    centroids = get_centroids(multi_labels, px_size, xx,yy)\n",
    "    pairs = pair_labels_to_particles(centroids, pos)\n",
    "\n",
    "    # for each particle\n",
    "    for j in range(len(multi_labels)):\n",
    "        # add data into array\n",
    "        X_new[count,:,:] = X_all[i,:,:]\n",
    "        mask_new[count,:,:] = multi_labels[pairs[j][1]]\n",
    "\n",
    "        # get defect label from metadata\n",
    "        if metadata.iloc[i][\"particle_%02i\" % j][\"N_defects\"] > 0:\n",
    "            Y_new[count, 1] = 1\n",
    "        else:\n",
    "            Y_new[count, 0] = 1\n",
    "\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f7ab38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(data):\n",
    "    # Reshape the data into a 2D array\n",
    "    nsamples, nx, ny = data.shape\n",
    "    data = data.reshape((nsamples, nx*ny))\n",
    "    \n",
    "    # Normalize the data\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(data)\n",
    "    data = scaler.transform(data)\n",
    "    \n",
    "    return data, scaler\n",
    "\n",
    "def split_and_transform(data, labels, scaler, split):\n",
    "    # Normalize the data using the scaler\n",
    "    #data = scaler.transform(data)\n",
    "    \n",
    "    # Split the data into training, validation, and testing sets\n",
    "    N_data = data.shape[0]\n",
    "    N_train = int(N_data * split[0])\n",
    "    N_val = int(N_data * split[1])\n",
    "    N_test = int((N_data *split[2]))\n",
    "    \n",
    "    train_data = data[:N_train, :]\n",
    "    train_labels = labels[:N_train, :]\n",
    "    val_data = data[N_train:N_train+N_val, :]\n",
    "    val_labels = labels[N_train:N_train+N_val, :]\n",
    "    test_data = data[N_train+N_val:N_train+N_val+N_test, :]\n",
    "    test_labels = labels[N_train+N_val:N_train+N_val+N_test, :]\n",
    "    \n",
    "    # Transform the data into PyTorch tensors and reshape\n",
    "    train_data = torch.from_numpy(train_data).to(torch.float32).reshape(-1, 512, 512)[:, None, :, :]\n",
    "    val_data = torch.from_numpy(val_data).to(torch.float32).reshape(-1, 512, 512)[:, None, :, :]\n",
    "    test_data =  torch.from_numpy(test_data).to(torch.float32).reshape(-1, 512, 512)[:, None, :, :]\n",
    "    \n",
    "    return train_data, train_labels, val_data, val_labels, test_data, test_labels\n",
    "\n",
    "# Normalize the defect data\n",
    "defect_data = X_new*mask_new\n",
    "defect_data, scaler = normalize(defect_data)\n",
    "#X_new , scaler = normalize(X_new)\n",
    "# Splitting the data into training, validation, and testing sets\n",
    "train_split, val_split, test_split = 0.7, 0.2, 0.1\n",
    "\n",
    "# Split and transform the defect data\n",
    "\n",
    "train_data, train_labels, val_data, val_labels, test_data, test_labels = split_and_transform(defect_data, Y_new, scaler, (train_split, val_split, test_split))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a4b3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DefectCountDataset(Dataset):\n",
    "    def __init__(self, images, labels, transform=None, target_transform=None):\n",
    "        self.img = images\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.img[idx,:,:]\n",
    "        label = self.labels[idx]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        return image, label\n",
    "\n",
    "train_dataset = DefectCountDataset(train_data, train_labels)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "\n",
    "val_dataset = DefectCountDataset(val_data, val_labels)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "\n",
    "test_dataset = DefectCountDataset(test_data, test_labels)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=16, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77ef227",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flatten(torch.nn.Module):\n",
    "    def forward(self, input):\n",
    "        if len(input.shape) < 4:\n",
    "            input = input[None,:,:,:]\n",
    "           \n",
    "        else:\n",
    "            input = input\n",
    "        #input = input.reshape(input.size(0), -1)\n",
    "        return input.reshape(-1, input.size(1)*input.size(2)*input.size(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5327d15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class ClassificationNN(nn.Module):\n",
    "    def __init__(self, input_channel, num_classes, num_conv_layers, conv_output_channels, kernel_size, stride, padding, \n",
    "                 activations,dropout_probs, use_batchnorm, use_maxpool,Maxpool_size, Height, Width):\n",
    "        super(ClassificationNN, self).__init__()\n",
    "        \n",
    "        # Initialize list of layers\n",
    "        layers = []\n",
    "        \n",
    "        # Create convolutional layers\n",
    "        for i in range(num_conv_layers):\n",
    "            # Create convolutional layer\n",
    "            conv = nn.Conv2d(in_channels=input_channel,out_channels=conv_output_channels[i],kernel_size=kernel_size,stride =stride,padding=padding)\n",
    "            # Initialize weights using Kaiming initialization\n",
    "            nn.init.kaiming_normal_(conv.weight, nonlinearity='relu')\n",
    "            input_channel = conv_output_channels[i]\n",
    "            \n",
    "            # Add convolutional layer to model\n",
    "            layers.append(conv)\n",
    "            \n",
    "            # Add activation function\n",
    "            layers.append(activations[i])\n",
    "\n",
    "            # Calulate what the final dimensions will be (w/o Maxpool, see below)\n",
    "            New_Height = ((Height - kernel_size + 2*padding)//stride + 1)\n",
    "\n",
    "            New_Width = ((Width - kernel_size + 2*padding)//stride + 1)\n",
    "\n",
    "            # Add dropout layer if specified\n",
    "            if dropout_probs[i] > 0:\n",
    "                dropout_layer = nn.Dropout2d(p=dropout_probs[i])\n",
    "                if not self.training:\n",
    "                    dropout_layer.p = 0\n",
    "                layers.append(dropout_layer)\n",
    "\n",
    "            # Add batch normalization layer if specified\n",
    "            if use_batchnorm[i]:\n",
    "                layers.append(nn.BatchNorm2d(conv_output_channels[i]))\n",
    "            \n",
    "            # Add max pooling layer if specified\n",
    "            if use_maxpool[i]:\n",
    "                layers.append(nn.AvgPool2d(Maxpool_size))\n",
    "                # Calulate what the final dimensions will be (if there's a maxpool)\n",
    "                New_Height = New_Height  // Maxpool_size\n",
    "                New_Width = New_Width // Maxpool_size\n",
    "\n",
    "            # Update the final dimensions values\n",
    "            Height = New_Height\n",
    "            Width = New_Width\n",
    "            #print(Width)\n",
    "                    \n",
    "        # Flatten layer\n",
    "        layers.append(Flatten())\n",
    "\n",
    "\n",
    "        # Add fully connected layer\n",
    "        Dims = conv_output_channels[i] * (New_Height*New_Width)\n",
    "        layers.append(nn.Linear(Dims, num_classes ))\n",
    "        \n",
    "        # Add softmax activation function\n",
    "        layers.append(nn.Softmax(dim=1))\n",
    "        \n",
    "        # Create Sequential model\n",
    "        self.Conv_layers = nn.Sequential(*layers)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.Conv_layers(x)\n",
    "\n",
    "# Define model\n",
    "model = ClassificationNN(input_channel=1, num_classes=2, num_conv_layers=3, conv_output_channels = [8, 16,16], kernel_size = 7, stride = 2,\n",
    "                         padding = 2,activations=[nn.ReLU(),nn.ReLU(),nn.ReLU()],dropout_probs = [0.05, 0.15, 0.1], use_batchnorm=[False, True, False], \n",
    "                         use_maxpool=[True, True, False], Maxpool_size = 2, Height = 512, Width = 512)\n",
    "print(model)\n",
    "#nn.Tanh(),nn.Tanh(),nn.Tanh(),nn.Tanh(),nn.Tanh(),nn.Tanh()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20d19e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = optim.RMSprop(model.parameters(), lr=1, weight_decay =0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e466f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import StepLR\n",
    "# Initialize empty lists to store training and validation losses\n",
    "train_loss = []\n",
    "val_loss = []\n",
    "learning_rates = []\n",
    "# Set the number of epochs to train the model\n",
    "n_epochs = 30\n",
    "\n",
    "# Define the learning rate scheduler\n",
    "scheduler = StepLR(optimizer, step_size= 5, gamma=0.5)\n",
    "\n",
    "# Loop over the number of epochs\n",
    "for epoch in range(1, n_epochs+1): \n",
    "    # Initialize running training and validation losses to 0\n",
    "    running_loss_train = 0.0\n",
    "    running_loss_val = 0.0\n",
    "    \n",
    "    # Set the model to train mode\n",
    "    model.train()\n",
    "    \n",
    "    # Loop over the training data\n",
    "    for train_data in train_dataloader:\n",
    "        # Clear the gradients of all optimized variables\n",
    "        optimizer.zero_grad()\n",
    "        # Retrieve images and image labels from the dataloader\n",
    "        train_images, train_labels = train_data\n",
    "        # Forward pass: compute predicted outputs by passing inputs to the model\n",
    "        train_outputs = model(train_images)\n",
    "        # Calculate the loss\n",
    "        loss = criterion(train_outputs, train_labels)\n",
    "        # Backward pass: compute gradient of the loss with respect to model parameters\n",
    "        loss.backward()\n",
    "        # Perform a single optimization step (parameter update)\n",
    "        optimizer.step()\n",
    "        # Update the running training loss\n",
    "        running_loss_train += loss.item() \n",
    "        \n",
    "    # Set the model to evaluation mode\n",
    "    model.eval()  \n",
    "    \n",
    "    # Loop over the validation data with torch.no_grad() to disable gradient calculations\n",
    "    with torch.no_grad():\n",
    "        for val_data in val_dataloader:\n",
    "            # Retrieve images and image labels from the dataloader\n",
    "            val_images, val_labels = val_data\n",
    "            # Forward pass: compute predicted outputs by passing inputs to the model\n",
    "            val_outputs = model(val_images)\n",
    "            # Calculate the loss\n",
    "            loss = criterion(val_outputs, val_labels)\n",
    "            # Update the running validation loss\n",
    "            running_loss_val += loss.item()\n",
    "        \n",
    "    # Calculate and store the average training loss for the epoch\n",
    "    running_loss_train /= len(train_dataloader)\n",
    "    train_loss.append(running_loss_train)\n",
    "    \n",
    "    # Calculate and store the average validation loss for the epoch\n",
    "    running_loss_val /= len(val_dataloader)\n",
    "    val_loss.append(running_loss_val)\n",
    "\n",
    "    # retrieve the learning rate at the current epoch\n",
    "    lr = optimizer.param_groups[0]['lr']\n",
    "    # store the learning rate in a list\n",
    "    learning_rates.append(lr)\n",
    "\n",
    "    # Print the average training and validation losses for the epoch\n",
    "    print('Epoch: {}/{} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f} \\tlr: {:.10f}'.format(\n",
    "        epoch, \n",
    "        n_epochs,\n",
    "        running_loss_train,\n",
    "        running_loss_val,\n",
    "        lr\n",
    "        ))\n",
    "    \n",
    "\n",
    "    # Step the learning rate scheduler\n",
    "    scheduler.step()\n",
    "    \n",
    "# Plot the training and validation losses\n",
    "plt.plot(range(1,n_epochs+1), train_loss, 'g', label='Training loss')\n",
    "plt.plot(range(1,n_epochs+1), val_loss, 'r', label='Validation loss')\n",
    "plt.title('Training and Validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9fa33bf",
   "metadata": {},
   "outputs": [],
   "source": [
    " # set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# initialize variables to store the total number of correct predictions and total number of predictions\n",
    "correct = 0\n",
    "total = 0\n",
    "running_loss_test = 0\n",
    "N_images = len(test_data)*2\n",
    "# since we're not training, we don't need to calculate the gradients for our outputs\n",
    "with torch.no_grad():\n",
    "    for data in test_dataloader:\n",
    "        images, labels = data\n",
    "        # calculate outputs by running images through the network\n",
    "        outputs = model(images)       \n",
    "        # the class with the highest energy is what we choose as prediction\n",
    "        _, predicted = torch.max(outputs.data,1)\n",
    "        _, label = torch.max(labels.data,1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == label).sum().item()\n",
    "\n",
    "print(f'Accuracy of the network on the {N_images} test images: {100 * correct // total} %')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "486fc8ce17fb909ebc26a9549a8e9ee69b34e1182be5d7f510e3ad8af0727554"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
